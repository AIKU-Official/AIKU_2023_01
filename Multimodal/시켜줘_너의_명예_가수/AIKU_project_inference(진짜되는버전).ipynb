{"cells":[{"cell_type":"markdown","metadata":{"id":"qI-wDbQDmSjx"},"source":["Training notebook for [Diff-SVC](https://github.com/prophesier/diff-svc) originally made by [justinjohn-03](https://github.com/justinjohn0306)\n"," Modified by [奕晨](https://twitter.com/nekrothecorpse) of [Archivoice](https://github.com/archivoice) and currently maintained by [haru0l](https://twitter.com/mscoocoo2)\n","\n","Please don't use this thing for illegal stuff like copying the voices of celebs and such. Just make sure you have permission!\n","\n","No redistribution allowed! No saving either.\n","\n","Support us over on Ko-Fi!\n","\n","[haru0l](https://ko-fi.com/haru0l)\n","\n","[julieraptor](https://ko-fi.com/julieraptor)\n","\n","[MLo7](https://ko-fi.com/m_lo7)\n","\n","[justinjohn-03](https://ko-fi.com/justinjohn03)"]},{"cell_type":"markdown","metadata":{"id":"G6guqBnrD3qb"},"source":["# Check Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"WcC2XWVgC4T0"},"outputs":[],"source":["#@title #Check GPU type\n","#@markdown this is for checking the GPU type you have as well as the available amount of vram.\n","!nvidia-smi -L\n","!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19282,"status":"ok","timestamp":1688015139327,"user":{"displayName":"조혜진","userId":"09399593881356851820"},"user_tz":-540},"id":"VSyF4oZhDxgW","outputId":"914c17cf-a265-42cb-ad58-f3a442fecea2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","Mounted at /content/drive\n","Done!\n"]}],"source":["#@title #Mount Google Drive\n","\n","#@markdown Makes your life easier when uploading and saving stuff.\n","\n","from google.colab import drive\n","drive.flush_and_unmount()\n","!rm -rf /content/drive\n","drive.mount('/content/drive')\n","print('Done!')"]},{"cell_type":"markdown","metadata":{"id":"MGNHNSGcEFHj"},"source":["# Preparation"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"elapsed":146127,"status":"error","timestamp":1688014899625,"user":{"displayName":"조혜진","userId":"09399593881356851820"},"user_tz":-540},"id":"IYxufeQ9EKuY","outputId":"53f292b6-710d-4c9b-f072-87d1a9c467e3"},"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e8dea2358e48>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Restarting notebook... continue as usual. This is normal. your notebook has not crashed please just continue STOP ASKING ABOUT THIS ITS FINE THIS IS NOT AN ERRORRRRRRR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mException\u001b[0m: Restarting notebook... continue as usual. This is normal. your notebook has not crashed please just continue STOP ASKING ABOUT THIS ITS FINE THIS IS NOT AN ERRORRRRRRR"]}],"source":["from IPython.display import clear_output\n","import time\n","import os\n","#@title #Step 1: Setup (part 1)\n","\n","#@markdown 【TERMS OF USE】\n","\n","#@markdown Disclaimer:\n","\n","#@markdown By using this notebook, you automaticaly agree that you will NOT clone a person's voice WITHOUT express permission and you may NOT monetize from this.\n","\n","#@markdown The authors of this notebook, neither will the developers will NOT assume responsibility for YOUR action for using this project. Only YOU as the user will take responsibility for your action.\n","\n","#@markdown You are also forbidden to download or share the notebook to anyone.\n","\n","#@markdown If you agree with the terms above, feel free to use the notebook\n","\n","!pip install pydub torchcrepe==0.0.17 pyworld==0.3.1 praat-parselmouth==0.4.1 scikit-image==0.19.3 ipython ipykernel pyloudnorm==0.1.0 webrtcvad h5py==3.7.0 einops==0.6.0 pycwt==0.3.0a22 torchmetrics==0.5 pytorch_lightning==1.3.3 numba==0.56.3 --quiet\n","!pip install torch==1.13.1 torchvision torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n","!pip install --pre torchtext==0.6.0 --no-deps --quiet\n","!pip install tensorboard<2.9,>=2.8 --quiet\n","%reload_ext tensorboard\n","#@markdown ---\n","#@markdown ###Select which fork to use\n","#@markdown The official repo is up-to-date, while UtaUtaUtau's version has Harvest support for improved f0.\n","fork = \"UtaUtaUtau's Repo\" #@param [\"Official Diff-SVC Repo\", \"UtaUtaUtau's Repo\"]\n","\n","if fork == \"Official Diff-SVC Repo\":\n","    !git clone -q https://github.com/prophesier/diff-svc\n","else:\n","    !git clone -q --branch harvest-preprocess https://github.com/UtaUtaUtau/diff-svc\n","%cd \"diff-svc\"\n","\n","hifigan_24k = \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/models_24khz/hifigan_24k.zip\"\n","hifigan_44k = \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/start/hifigan_44k.zip\"\n","checkpoints = \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/start/checkpoints.zip\"\n","\n","!wget {checkpoints} && unzip checkpoints.zip && rm checkpoints.zip\n","!wget {hifigan_44k} && unzip hifigan_44k.zip -d checkpoints && rm hifigan_44k.zip\n","!wget {hifigan_24k} && unzip hifigan_24k.zip && rm hifigan_24k.zip\n","\n","clear_output()\n","exit()\n","raise Exception('Restarting notebook... continue as usual. This is normal. your notebook has not crashed please just continue STOP ASKING ABOUT THIS ITS FINE THIS IS NOT AN ERRORRRRRRR')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"tCJNxu-nTdJb"},"outputs":[],"source":["#@markdown ## Setup (part 2)\n","from IPython.display import clear_output\n","\n","#@markdown ###Model sample rate\n","#@markdown Please choose if you want to train a 24kHz model or a 44.1kHz model.\n","\n","sample_rate = '44.1kHz' #@param [\"24kHz\", \"44.1kHz\"]\n","%cd \"/content/diff-svc\"\n","%mkdir -p checkpoints\n","\n","if sample_rate == \"44.1kHz\":\n","    config_path = \"/content/diff-svc/training/config_nsf.yaml\"\n","else:\n","    config_path = \"/content/diff-svc/training/config.yaml\"\n","    !rm {config_path}\n","    !wget \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/models_24khz/config.yaml\" -O {config_path} -q\n","\n","#!pip install pyworld==0.3.1\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":437,"status":"ok","timestamp":1687943321289,"user":{"displayName":"조혜진","userId":"09399593881356851820"},"user_tz":-540},"id":"7nAx7UOUHX_H","outputId":"49d87a49-fda7-435e-f2bb-cf802e6fbf6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["No dataset loaded. You have not specified a path.\n"]}],"source":["import os\n","import subprocess\n","from pydub import AudioSegment\n","import re\n","from IPython.display import clear_output\n","import wave\n","import shutil\n","%cd \"/content/diff-svc\"\n","#@title #Step 2: Decompress dataset\n","#@markdown This should work with most common archive formats, so don't worry. Please stick with the alphabet characters otherwise preprocessing might error out.\n","\n","#@markdown Supported types: `.rar`, `.zip`, `.tar`, `.tar.gz`, `.tar.bz2`, `.7z`\n","\n","#@markdown ###Note that your dataset should consist of `.wav` or `.ogg` format audio\n","#@markdown ---\n","#@markdown Name your singer.\n","singer_name = 'Yoo' #@param {type: \"string\"}\n","\n","#@markdown ---\n","#@markdown ###Cleanup folders\n","#@markdown Checking this will delete the folder in case you made any errors and need to rerun this cell.\n","cleanup = True #@param {type: \"boolean\"}\n","\n","if cleanup:\n","  !rm -rf \"data/raw\"\n","\n","\n","if singer_name == '' or singer_name.replace(\" \", \"\") == '' or singer_name.replace(\" \", \"\") == '':\n","  print(\"Put a singer name.\")\n","else:\n","  singer_name = re.sub(r'[àáâãäåèéêëìíîïòóôõöùúûüýÿÀÁÂÃÄÅÈÉÊËÌÍÎÏÒÓÔÕÖÙÚÛÜÝñ]', lambda m: m.group(0)[0], singer_name)\n","  singer_name = singer_name.replace(\" \", \"_\")\n","  clear_output()\n","\n","  if sample_rate == \"44.1kHz\":\n","      !sed -i -r 's/nyaru/{singer_name}/g' {config_path}\n","  else:\n","      !sed -i -r 's/atri/{singer_name}/g' {config_path}\n","\n","  #@markdown ---\n","  #@markdown File location\n","  !mkdir -p data/raw\n","  dataset_location = '' #@param {type: \"string\"}\n","  diffsvc_location = os.path.join('data', 'raw', singer_name, \"\")\n","  if dataset_location == '' or dataset_location.replace(\" \", \"\") == '' or dataset_location.replace(\" \", \"\") == '':\n","    print(\"No dataset loaded. You have not specified a path.\")\n","  else:\n","    if dataset_location.endswith('.rar'):\n","        !unrar x \"$dataset_location\" \"$diffsvc_location\"\n","    elif dataset_location.endswith('.zip'):\n","        !unzip \"$dataset_location\" -d \"$diffsvc_location\"\n","    elif dataset_location.endswith('.tar'):\n","        !tar -xf \"$dataset_location\" -C \"$diffsvc_location\"\n","    elif dataset_location.endswith('.tar.gz'):\n","        !tar -xzf \"$dataset_location\" -C \"$diffsvc_location\"\n","    elif dataset_location.endswith('.tar.bz2'):\n","        !tar -xjf \"$dataset_location\" -C \"$diffsvc_location\"\n","    else:\n","        !7za x \"$dataset_location\" -o$diffsvc_location\n","\n","    root_folder = diffsvc_location\n","\n","    # create a list to store the converted audio files\n","    converted_files = []\n","\n","    # loop through all subfolders and files in the root folder\n","    for subdir, dirs, files in os.walk(root_folder):\n","        for file in files:\n","            # get the file path\n","            file_path = os.path.join(subdir, file)\n","            # check if the file is an audio file\n","            if file.endswith('.mp3') or file.endswith('.wav') or file.endswith('.flac') or file.endswith('.ogg'):\n","                try:\n","                    # load the audio file\n","                    audio = AudioSegment.from_file(file_path)\n","                    # check if the file is shorter than 3 seconds\n","                    if audio.duration_seconds < 3:\n","                        os.remove(file_path)\n","                    else:\n","                        # convert the audio file to WAV format\n","                        audio = audio.set_frame_rate(44100).set_sample_width(2).set_channels(1)\n","                        new_file_path = os.path.join(subdir, 'wav_' + str(len(converted_files) + 1) + '.wav')\n","                        audio.export(new_file_path, format='wav')\n","                        # add the new file to the list of converted files\n","                        converted_files.append(new_file_path)\n","                        # remove the original file\n","                        os.remove(file_path)\n","                except Exception as e:\n","                    print(f'Error converting {file_path} : {e}')\n","                    os.remove(file_path)\n","            else:\n","                os.remove(file_path)\n","  #clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"AbGW1MheDW2x"},"outputs":[],"source":["import os\n","import subprocess\n","from pydub import AudioSegment\n","import yaml\n","from IPython.display import clear_output\n","import re\n","\n","#@title #Step 2-A: Decompress training data\n","#@markdown Decompresses training data directly to `diff-svc/data/binary`, usable only if you already have the output files of Step 4. The files from this should be in your Google Drive.\n","\n","#@markdown If you run this step, please skip step 4.\n","%cd \"/content/diff-svc\"\n","#@markdown ---\n","#@markdown File location\n","!mkdir -p data/binary\n","preprocessed_data_location = '' #@param {type: \"string\"}\n","config_location = '' #@param {type: \"string\"}\n","diffsvc_bin_location = 'data'\n","\n","os.environ['PYTHONPATH']='.'\n","with open(config_location, 'r') as config_file:\n","    config = yaml.safe_load(config_file)\n","    singer_name = config['speaker_id']\n","\n","singer_name = re.sub(r'[àáâãäåèéêëìíîïòóôõöùúûüýÿÀÁÂÃÄÅÈÉÊËÌÍÎÏÒÓÔÕÖÙÚÛÜÝñ]', lambda m: m.group(0)[0], singer_name)\n","\n","#@markdown ---\n","#@markdown ###Cleanup folders\n","#@markdown Checking this will delete the folder in case you made any errors and need to rerun this cell.\n","cleanup = False #@param {type: \"boolean\"}\n","\n","if cleanup:\n","  !rm -rf \"data/binary\"\n","\n","print(\"Processing....\")\n","\n","\n","singer_name = singer_name.replace(\" \", \"_\")\n","clear_output()\n","if sample_rate == \"44.1kHz\":\n","  !sed -i -r 's/nyaru/{singer_name}/g' {config_path}\n","else:\n","  !sed -i -r 's/atri/{singer_name}/g' {config_path}\n","\n","if preprocessed_data_location == '' or preprocessed_data_location.replace(\" \", \"\") == '' or preprocessed_data_location.replace(\" \", \"\") == '':\n","  print(\"No dataset loaded. You have not specified a path.\")\n","else:\n","  if preprocessed_data_location.endswith('.rar'):\n","      !unrar x \"$preprocessed_data_location\" \"$diffsvc_bin_location\"\n","  elif preprocessed_data_location.endswith('.zip'):\n","      !unzip \"$preprocessed_data_location\" -d \"$diffsvc_bin_location\"\n","  elif preprocessed_data_location.endswith('.tar'):\n","      !tar -xf \"$preprocessed_data_location\" -C \"$diffsvc_bin_location\"\n","  elif preprocessed_data_location.endswith('.tar.gz'):\n","      !tar -xzf \"$preprocessed_data_location\" -C \"$diffsvc_bin_location\"\n","  elif preprocessed_data_location.endswith('.tar.bz2'):\n","      !tar -xjf \"$preprocessed_data_location\" -C \"$diffsvc_bin_location\"\n","  else:\n","      !7za x \"$preprocessed_data_location\" -o$diffsvc_bin_location\n","\n","if config_location == '' or config_location.replace(\" \", \"\") == '' or config_location.replace(\" \", \"\") == '':\n","  print(\"No config loaded. You have not specified a path.\")\n","else:\n","  if sample_rate == \"44.1kHz\":\n","    !cp -r {config_location} training\n","\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"kc4uiI1WLsI7"},"source":["# Step 3: Training Options/Parameters\n","Unfortunately, you can not get away with no editing, not completely that is."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"CEWhfwEmLoQx"},"outputs":[],"source":["%cd /content/diff-svc\n","\n","import re\n","import os\n","os.environ['PYTHONPATH']='.'\n","with open(config_path, \"r\") as f:\n","    yaml_file = f.read()\n","\n","yaml_file = re.sub(r'load_ckpt: \\S+', 'load_ckpt: \"\"', yaml_file)\n","\n","with open(config_path, \"w\") as f:\n","    f.write(yaml_file)\n","\n","#@markdown ###F0 extraction method\n","#@markdown Crepe is used for F0 extraction for data preprocessing, while it is of higher quality, it is slow, therefore set to false as default.\n","\n","#@markdown Unchecking this while using the official repo will default to parselmouth, while using UtaUtaUtau's repo will use harvest.\n","use_crepe = False #@param {type: \"boolean\"}\n","\n","#@markdown ---\n","#@markdown ###Use custom save directory\n","#@markdown You can change the directory to save wherever you want. Default location is /diff-svc/checkpoint if unchanged.\n","\n","#@markdown Please point to a directory with the singer name already specified (example /content/drive/MyDrive/diff-svc/nyaru)\n","\n","use_save_dir = False #@param {type: \"boolean\"}\n","\n","save_dir = \"checkpoints\" #@param {type: \"string\"}\n","#save_dir.strip() check for issues, disabling temporarily\n","\n","#@markdown ---\n","#@markdown ###Resume training from a checkpoint\n","\n","resume_training_from_ckpt = False #@param {type: \"boolean\"}\n","ckpt_directory = \"\" #@param {type: \"string\"}\n","\n","#@markdown ---\n","\n","#@markdown ###Setup for small datasets\n","#@markdown If your dataset is small, each epoch will go by very fast and won't have enough time to train well, so if your dataset is considered small, use this option.\n","\n","endless_ds = True #@param {type:\"boolean\"}\n","\n","if use_save_dir:\n","  !rm -rf utils/hparams.py\n","  !wget https://github.com/prophesier/diff-svc/raw/main/utils/hparams.py -O utils/hparams.py\n","  !sed -i -r 's|checkpoints/\\{args.work_dir}|haruprivatewashere|g' /content/diff-svc/utils/hparams.py\n","  !sed -i -r 's|haruprivatewashere|{save_dir}|g' /content/diff-svc/utils/hparams.py\n","else:\n","  !rm -rf utils/hparams.py\n","  !wget https://github.com/prophesier/diff-svc/raw/main/utils/hparams.py -O utils/hparams.py\n","clear_output()\n","\n","if resume_training_from_ckpt:\n","  !cp {ckpt_directory} {save_dir}\n","  print(\"Status: Resuming Training From Checkpoint\")\n","else:\n","  print(\"Status: Not Resuming From Checkpoint\")\n","\n","batch_size = 12\n","if sample_rate == \"44.1kHz\":\n","  decay_steps = 40000\n","  disable_fs2 = True\n","else:\n","  decay_steps = 60000\n","  disable_fs2 = False\n","\n","!sed -i -r 's|(max_sentences:)(\\s+)(.+)|\\1\\2{batch_size}|g' {config_path}\n","!sed -i -r 's|(decay_steps:)(\\s+)(.+)|\\1\\2{decay_steps}|g' {config_path}\n","!sed -i -r 's|(use_crepe:)(\\s+)(.+)|\\1\\2{use_crepe}|g' {config_path}\n","!sed -i -r 's|(no_fs2:)(\\s+)(.+)|\\1\\2{disable_fs2}|g' {config_path}\n","!sed -i -r 's|(endless_ds:)(\\s+)(.+)|\\1\\2{endless_ds}|g' {config_path}\n","\n","#clear_output()"]},{"cell_type":"markdown","metadata":{"id":"4s-RqXnR-UOa"},"source":["# Training\n","Finally, the dreaded part."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"wsHTxKEO-ZwV"},"outputs":[],"source":["#@title #Step 4: Pre-processing\n","#@markdown This step is also known as data prep or feature generation, who cares?\n","#@markdown\n","\n","os.environ['PYTHONPATH']='.'\n","!CUDA_VISIBLE_DEVICES=0 python preprocessing/binarize.py --config {config_path}\n","%cd \"data\"\n","!7za -bso0 a \"../../{singer_name}_binary_data.7z\" \"binary/{singer_name}\"\n","\n","#@markdown ---\n","#@markdown ###Save binary to Google Drive\n","\n","#prolly remove this for porting this notebook to other platforms\n","save_binary_to_gd = False #@param {type: \"boolean\"}\n","\n","if save_binary_to_gd:\n","  if not os.path.exists('/content/drive/MyDrive/diff-svc/data/{singer_name}'):\n","      !mkdir -p /content/drive/MyDrive/diff-svc/data/{singer_name}\n","  !mv -v \"../../{singer_name}_binary_data.7z\" /content/drive/MyDrive/diff-svc/data/{singer_name}\n","  !cp -r {config_path} /content/drive/MyDrive/diff-svc/data/{singer_name}\n","else:\n","  !cp -r {config_path} ../../\n","%cd ../"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"L5ioLY0qkohN"},"outputs":[],"source":["#@title #Step 5-0 Tensorboard (run before step 5)\n","#@markdown Shows training progress, go to the top right corner to set it to update the logs.\n","\n","#@markdown ---\n","#@markdown ### 403 Forbidden error fix\n","fix_403 = False #@param {type: \"boolean\"}\n","%cd \"/content/diff-svc\"\n","import datetime, os\n","%reload_ext tensorboard\n","if use_save_dir:\n","  %tensorboard --reload_interval=1 --reload_multifile=true --logdir=\"{save_dir}/lightning_logs/\"\n","elif use_save_dir and fix_403:\n","  %tensorboard --reload_interval=1 --reload_multifile=true --logdir=\"{save_dir}/lightning_logs/\" --bind_all\n","elif fix_403:\n","  %tensorboard --reload_interval=1 --reload_multifile=true --logdir=checkpoints/{singer_name}/lightning_logs/ --bind_all\n","else:\n","  %tensorboard --reload_interval=1 --reload_multifile=true --logdir=checkpoints/{singer_name}/lightning_logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"NvlB1oCR_lxh"},"outputs":[],"source":["%cd \"/content/diff-svc\"\n","#@title #Step 5: Training\n","#@markdown Yeah, it took THAT long to get here, colab is probably going to disconnect you at this point... unless you have pro ¯\\\\_(ツ)_/¯\n","os.environ['PYTHONPATH']='.'\n","\n","!CUDA_VISIBLE_DEVICES=0 python run.py --config {config_path} --exp_name $singer_name --reset"]},{"cell_type":"markdown","metadata":{"id":"t8k1skYjXXo5"},"source":["# **Inference Section**"]},{"cell_type":"code","execution_count":16,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144129,"status":"ok","timestamp":1688020301213,"user":{"displayName":"조혜진","userId":"09399593881356851820"},"user_tz":-540},"id":"NuKR8QZOyVnH","outputId":"aa6c0ebb-9929-420c-8613-b4b7c26bdd71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inference complete!\n","Inferenced file is stored at results/sample.flac.\n"]}],"source":["import os\n","from IPython.display import clear_output\n","import yaml\n","%cd \"/content/diff-svc\"\n","#@title # **Load model**\n","\n","#@markdown ### **Load a trained model for inferencing**\n","#@markdown ___\n","\n","os.environ['PYTHONPATH']='.'\n","!CUDA_VISIBLE_DEVICES=0\n","\n","from utils.hparams import hparams\n","#latest confirmed\n","from preprocessing.data_gen_utils import get_pitch_parselmouth,get_pitch_crepe\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import IPython.display as ipd\n","import utils\n","import librosa\n","import torchcrepe\n","from infer import *\n","import logging\n","from infer_tools.infer_tool import *\n","\n","logging.getLogger('numba').setLevel(logging.WARNING)\n","\n","model_path = \"/content/drive/MyDrive/ML/AIKU_project/Singer/checkpoints_new3/model_ckpt_steps_200000.ckpt\" #@param {type: \"string\"}\n","project_name = \"sample\"\n","config_path= \"/content/drive/MyDrive/ML/AIKU_project/Singer/checkpoints_new3/config.yaml\" #@param {type: \"string\"}\n","hubert_gpu=True\n","svc_model = Svc(project_name,config_path,hubert_gpu, model_path)\n","print('model loaded')\n","\n","#@markdown Either put an audio file here or a folder for batch inferencing\n","wav_in = \"/content/drive/MyDrive/ML/AIKU_project/Singer/dataset/kitsch_gaudiolab_vocal.wav\" #@param {type:\"string\"}\n","\n","if wav_in == \"\":\n","  print(\"No input given. Using default audio for reference\")\n","  wav_in = \"/content/diff-svc/raw/test_input.wav\"\n","key = -6 #@param {type:\"slider\", min:-12, max:12, step:1}\n","\n","pndm_speedup = 10 #@param {type:\"slider\", min:0, max:100, step:1}\n","\n","wav_out = \"sample\"\n","\n","add_noise_step = 0 #@param {type:\"slider\", min:0, max:1000, step:10}\n","\n","thre = 0.85 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n","use_crepe= False #@param {type:\"boolean\"}\n","use_pe=False #@param {type:\"boolean\"}\n","use_gt_mel= False\n","\n","#totally not stolen\n","if os.path.isdir(wav_in):\n","  try:\n","    for name in os.listdir(wav_in):\n","      if name.endswith(\".wav\"):\n","        wav_fn = os.path.join(wav_in, name)\n","        print(wav_fn)\n","        !mkdir batch_results\n","        out_folder = \"batch_results\"\n","        wav_gen = os.path.join(out_folder, name)\n","        f0_tst, f0_pred, audio = run_clip(svc_model,file_path=wav_fn, key=key, acc=pndm_speedup, use_crepe=use_crepe, use_pe=use_pe, thre=thre,\n","                        use_gt_mel=use_gt_mel, add_noise_step=add_noise_step,project_name=project_name,out_path=wav_gen)\n","  except Exception as e:\n","    raise Exception(e)\n","\n","  !zip /content/batch_results.zip /content/diff-svc/batch_results/*.wav\n","  clear_output()\n","  print(\"Inference complete!\")\n","  print(f\"Inferenced file is stored at batch_results or a zipped folder in /content/.\")\n","else:\n","  try:\n","    f0_tst, f0_pred, audio = run_clip(svc_model,file_path=wav_in, key=key, acc=pndm_speedup, use_crepe=use_crepe, use_pe=use_pe, thre=thre, use_gt_mel=use_gt_mel, add_noise_step=add_noise_step,project_name=project_name,out_path=f\"results/{wav_out}.flac\")\n","    clear_output()\n","    print(\"Inference complete!\")\n","    print(f\"Inferenced file is stored at results/{wav_out}.flac.\")\n","  except Exception as e:\n","    raise Exception(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":93,"output_embedded_package_id":"12FZYgL66AStlB4vHWbOHtSwkyQlEXtmI"},"executionInfo":{"elapsed":56478,"status":"ok","timestamp":1687944427674,"user":{"displayName":"조혜진","userId":"09399593881356851820"},"user_tz":-540},"id":"LHa1-hYotBOs","outputId":"4d1924d2-90bb-4f72-8567-a3976520b337"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@markdown Show results (only for single inference)\n","\n","import os\n","if os.path.isfile('results/sample.flac'):\n","  print(\"slay mama\")\n","else:\n","  raise Exception(\"file not found you dumbo\")\n","from IPython.display import Audio\n","Audio('results/sample.flac')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/Archivoice/Diff-SVC-notebooks/blob/main/Diff_SVC_training_notebook_(colab_ver_).ipynb","timestamp":1686208931386}],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}